{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92004005-a055-4c44-97c5-a81d313beca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (5.20.1)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (4.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.115.11)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.7.2 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (1.7.2)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.27.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.29.2)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (3.10.7)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (2.1.4)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (10.2.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (2.9.2)\n",
      "Requirement already satisfied: pydub in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.9.10)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.46.1)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.12.5)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.31.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio-client==1.7.2->gradio) (2023.10.0)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio-client==1.7.2->gradio) (13.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (4.65.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.3.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.0.7)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e7a0557-da19-4c5c-bcd0-1d399e4821fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337a7629-1a02-4b93-8c3e-4f61e1d0faac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ollama version is 0.5.13\n"
     ]
    }
   ],
   "source": [
    "!ollama --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37ae9d8b-ea82-4adc-9902-da5783593e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               ID              SIZE      MODIFIED       \n",
      "llama3:8b          365c0bd3c000    4.7 GB    48 minutes ago    \n",
      "llama3.1:latest    46e0c10c039e    4.9 GB    2 hours ago       \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21e5e868-6db3-4eb0-9e7d-f55938e9fd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ‹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ™ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ¹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ¸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ¼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ´ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ¦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â § \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ‡ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â � \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ‹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ™ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ¹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ¸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ¼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â ¦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest â § \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 6a0746a1ec1a... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 4.7 GB                         \u001b[K\n",
      "pulling 4fa551d4f938... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  12 KB                         \u001b[K\n",
      "pulling 8ab4849b038c... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  254 B                         \u001b[K\n",
      "pulling 577073ffcc6c... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  110 B                         \u001b[K\n",
      "pulling 3f8eb4da87fa... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  485 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3:8b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3edc382c-260f-4410-b3e2-95c060208621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm just an AI, I don't have feelings or emotions like humans do. However, I'm functioning properly and ready to assist with any questions or tasks you may have! It's great to chat with you. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(\n",
    "    model=\"llama3:8b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello, how are you?\"}]\n",
    ")\n",
    "\n",
    "print(response[\"message\"][\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45b43c78-d648-444d-9736-6bc69a03eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize chat history\n",
    "chat_history = []\n",
    "\n",
    "def chat_with_llama3(user_input, history):\n",
    "    global chat_history  \n",
    "    \n",
    "    formatted_history = \"\\n\".join([f\"User: {msg['user']}\\nLLaMA: {msg['llama']}\" for msg in chat_history])\n",
    "    \n",
    "    # Combine user input with past history\n",
    "    prompt = f\"{formatted_history}\\nUser: {user_input}\\nLLaMA:\"\n",
    "    \n",
    "    # Get response from Model\n",
    "    response = ollama.chat(model=\"llama3:8B\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    \n",
    "    # Extract reply\n",
    "    llama_reply = response[\"message\"][\"content\"]\n",
    "    \n",
    "    # Append the new exchange to history\n",
    "    chat_history.append({\"user\": user_input, \"llama\": llama_reply})\n",
    "    \n",
    "    # Keep only the last 10 messages to optimize memory\n",
    "    chat_history = chat_history[-10:]\n",
    "    \n",
    "    return llama_reply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "107ff13b-4871-4672-aebd-f95693bf9220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp8cg\\anaconda3\\Lib\\site-packages\\gradio\\chat_interface.py:334: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_ui = gr.ChatInterface(\n",
    "    fn=chat_with_llama3,  \n",
    "    title=\"LLaMA 3.1 Chatbot\",\n",
    "    description=\"Chat with LLaMA 3.1 locally. It remembers past messages!\",\n",
    "    theme=\"soft\"\n",
    ")\n",
    "\n",
    "# Launch chatbot\n",
    "chat_ui.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0124ba6-f34a-4295-bda1-7a3409cbcaf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
